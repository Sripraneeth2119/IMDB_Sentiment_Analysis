{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2XZo-6wcVOT"
      },
      "source": [
        "##IMDB Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwDuOjo1v2HE"
      },
      "source": [
        "Firstly, import all the required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JL4FKL3dYXB7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuqKnlIaeRQp",
        "outputId": "106b7d96-40f7-4aed-d54b-d227071505d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WX9d7MWQe4Pj"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/labeledTrainData.tsv', delimiter=\"\\t\",quoting=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vzUjTOKzjFGq",
        "outputId": "bdd8eb4f-c696-45ff-e49e-cac2ad70d55b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-779a001d-2338-4ed5-a1b4-13f8968d46ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-779a001d-2338-4ed5-a1b4-13f8968d46ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-3c00b51a-0812-4b67-8ecd-abb4b600d462\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c00b51a-0812-4b67-8ecd-abb4b600d462')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-3c00b51a-0812-4b67-8ecd-abb4b600d462 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-779a001d-2338-4ed5-a1b4-13f8968d46ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-779a001d-2338-4ed5-a1b4-13f8968d46ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyRcOQDmiJqq"
      },
      "source": [
        "Tokenization of the data\n",
        "\n",
        "Initially we tokenize the sentences into words and later you stopwords inorder to eliminate the words which are not really essential for the sentence. Then we use Lemmatization inorder to get the meaningful output\n",
        "\n",
        "Here we have used the BeautifulSoup function in order to clear all the html tags and this can be in generally said to be a part of text preprocessing. WordnNetLemmatizer is used for lemmatizing the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7Yh2rv6EtpBB"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vbo3paNejQpf"
      },
      "outputs": [],
      "source": [
        "def process(review):\n",
        "    review = BeautifulSoup(review).get_text()\n",
        "    # without punctuation and numbers\n",
        "    review = re.sub(\"[^a-zA-Z]\",' ',review)\n",
        "    # lowercase and splitting to eliminate stopwords\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    swords = set(stopwords.words(\"english\"))\n",
        "    review = [lemmatizer.lemmatize(w) for w in review if w not in swords]\n",
        "    # we join splitted paragraphs with join before return..\n",
        "    return(\" \".join(review))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ECDQjhfpBA",
        "outputId": "08a49f12-493d-4ebf-995f-855706823cfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-5c54a9b076df>:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  review = BeautifulSoup(review).get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of reviews processed = 1000\n",
            "No of reviews processed = 2000\n",
            "No of reviews processed = 3000\n",
            "No of reviews processed = 4000\n",
            "No of reviews processed = 5000\n",
            "No of reviews processed = 6000\n",
            "No of reviews processed = 7000\n",
            "No of reviews processed = 8000\n",
            "No of reviews processed = 9000\n",
            "No of reviews processed = 10000\n",
            "No of reviews processed = 11000\n",
            "No of reviews processed = 12000\n",
            "No of reviews processed = 13000\n",
            "No of reviews processed = 14000\n",
            "No of reviews processed = 15000\n",
            "No of reviews processed = 16000\n",
            "No of reviews processed = 17000\n",
            "No of reviews processed = 18000\n",
            "No of reviews processed = 19000\n",
            "No of reviews processed = 20000\n",
            "No of reviews processed = 21000\n",
            "No of reviews processed = 22000\n",
            "No of reviews processed = 23000\n",
            "No of reviews processed = 24000\n",
            "No of reviews processed = 25000\n"
          ]
        }
      ],
      "source": [
        "# We clean our training data with the help of the above function:\n",
        "# We can see the status of the review process by printing a line after every 1000 reviews.\n",
        "\n",
        "train_x_tum = []\n",
        "for r in range(len(df[\"review\"])):\n",
        "    if (r+1)%1000 == 0:\n",
        "        print(\"No of reviews processed =\", r+1)\n",
        "    train_x_tum.append(process(df[\"review\"][r]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3_ly237pnFV"
      },
      "source": [
        "Converting words to vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqcrXDYvzzH_",
        "outputId": "2414edf6-e86d-4c7a-cb1b-09307644fee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.13)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nB7E6QnTwLjn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "50-3eZwS3D1c"
      },
      "outputs": [],
      "source": [
        "vol_size = 10000 #Consider the vocabulary to be 10000. The more we consider this, the OHE will be that big"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bxauxCPW4JjK"
      },
      "outputs": [],
      "source": [
        "onehot_repr = [one_hot(words,vol_size) for words in train_x_tum]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBOKl_Gw6Oyo",
        "outputId": "2e7aa81c-16e4-464b-861b-8100fe13ae71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8635 8904 6999 ... 5651   70 8407]\n",
            " [   0    0    0 ... 1879 5670  472]\n",
            " [6231 2556 3682 ... 2558 7132 5441]\n",
            " ...\n",
            " [   0    0    0 ... 6999 6590 5701]\n",
            " [   0    0    0 ...  774 8916 5000]\n",
            " [   0    0    0 ... 5268 9696 3731]]\n"
          ]
        }
      ],
      "source": [
        "embedded_docs = pad_sequences(onehot_repr,padding='pre',maxlen=200)\n",
        "print(embedded_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vjhsZIsf2q7"
      },
      "source": [
        "Model Building\n",
        "\n",
        "LSTM model is built using the tensorflow library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXJUBzEWeT2-",
        "outputId": "fc5aacce-c15c-4d70-827f-d8065955f2bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 40)           400000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               56400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 456,501\n",
            "Trainable params: 456,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vol_size,40,input_length=200))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-UgtZ_p9fHtZ"
      },
      "outputs": [],
      "source": [
        "X_final = np.array(embedded_docs)\n",
        "y_final = np.array(df['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqpaCkdJfc5Z",
        "outputId": "61bb4afb-3c48-414d-f040-0e3666367413"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 200), (25000,))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_final.shape,y_final.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwOGSXTpfm9_"
      },
      "source": [
        "Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tEa4c1A_fhB8"
      },
      "outputs": [],
      "source": [
        "callback= EarlyStopping(monitor='accuracy',mode='max',verbose=1,patience=5)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_final,y_final, train_size=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICauaJrMfzUn",
        "outputId": "dc45a73f-0777-486b-ad9d-93e4527ae380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 146s 107ms/step - loss: 0.1633 - accuracy: 0.7647 - val_loss: 0.1407 - val_accuracy: 0.8033\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 43s 35ms/step - loss: 0.0980 - accuracy: 0.8756 - val_loss: 0.1261 - val_accuracy: 0.8306\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.0569 - accuracy: 0.9282 - val_loss: 0.1260 - val_accuracy: 0.8281\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.0378 - accuracy: 0.9560 - val_loss: 0.1356 - val_accuracy: 0.8191\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.0316 - accuracy: 0.9623 - val_loss: 0.1397 - val_accuracy: 0.8242\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 0.0245 - accuracy: 0.9711 - val_loss: 0.1517 - val_accuracy: 0.8043\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.0389 - accuracy: 0.9511 - val_loss: 0.1536 - val_accuracy: 0.8141\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 0.0212 - accuracy: 0.9750 - val_loss: 0.1508 - val_accuracy: 0.8181\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.0128 - accuracy: 0.9859 - val_loss: 0.1548 - val_accuracy: 0.8173\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.0101 - accuracy: 0.9892 - val_loss: 0.1573 - val_accuracy: 0.8139\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ff019f4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.fit(X_train,y_train, validation_data=(X_test,y_test),epochs=10,batch_size=8,callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rSqQfk2PgEsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70173888-bcd8-4961-b0d3-ffd4c85e6a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 3s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "test_predict = model.predict(X_test)\n",
        "acc = roc_auc_score(y_test, test_predict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: % \", acc * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LaFRxHR8BU3",
        "outputId": "90419363-7b26-402f-f8ac-8b9c52de63d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: %  87.67729829603441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Conclusion\n",
        "\n",
        "In this project, I have implemented the LSTM model in order to solve the natural language problem of IMDB reviews sentiment analysis. I have initially tokenised the reviews and then lemmatizied the words in order to make it the words more valuable. Now this obtained data is then converted into vectors using one hot encoder. This is further given to the LSTM model and obtained the accuracy of 87.70%"
      ],
      "metadata": {
        "id": "MmT8V1Np5Obf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "65M2IPn3DBfn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}